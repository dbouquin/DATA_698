{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A long short-term memory recurrent neural network for generating astrophysics-specific language and assessment using tf-idf, cosine similarity, and presence of non-ASCII characters to determine model effectiveness\n",
    "### Daina Bouquin\n",
    "## Summary of Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below sections outline the results of an analysis initially geared toward testing the following hyptheses. \n",
    "\n",
    "**Some subdomains of astronomy will be more acurately generated by the LSTM ANN than others.** \n",
    "\n",
    "A. The ability to generate a similar title to those available to train the model in the original training sets will be different between fields that are more emergent compared with those that are more established. For instance, I hypothesize that the LSTM ANN will be more effective in generating titles based on the \"black hole\" data than on the \"exoplanet\" data as the exoplanet field is much less established and therefore likely less regular from a linguistics perspective than text discussing black holes.\n",
    "\n",
    "   \n",
    "* Black Holes - earliest publication available in ADS is 1799 \n",
    "* Astrobiology - earliest publication available in ADS is 1870 \n",
    "* Exoplanets - earliest publication available in ADS is 1943 \n",
    "\n",
    "This hypothesis has been shown to be true in regards to an LSTM trained real astronomy titles from the Astrophysics Data System. The real titles were used to train the neural network and each trained model output 10,000 RNN-generated titles based on the training data; training datasets consisted of corpus sizes of 1,000 to 20,000 titles. The highest degree of accuracy achieved by the LSTM RNN for each subdomain of astronomy is listed below. You can see that the most established field (black holes) has the lowest cosine similarity measure achieved across all tests, while the most emergent field (exoplanets) was not able to achieve a cosine similarity measure better than 45.81 degrees.\n",
    "\n",
    "| Astronomy Domain        | Minimum Cosine Similarity Angle        | \n",
    "| ------------- |:-------------:| \n",
    "| Black Holes     | 30.6 | \n",
    "| Astrobiology      |  32.4   | \n",
    "| Exoplanets | 45.81     | \n",
    "\n",
    "Moreover, as training sizes increased, the accuracy as measured through cosine similarity improved for both the black hole and exoplanets tests (violin plots below); the improvements were subtle and this is likely due to not having a much higher capacity to process larger datasets. Running torch (the analysis module I implemented in Python) without access to a GPU and GPU acceleration through CUDA necessarily limited my ability to train models using larger datasets. \n",
    "\n",
    "<img src=\"blackhole_summary.png\",width=600>\n",
    "<img src=\"exoplanet_summary.png\",width=600>\n",
    "\n",
    "Interestingly, for the cosine similarity analysis performed on the RNN-generated titles that were trained on the most interdisciplinary field (astrobiology), there was no obvious improvement across training set sizes. There seemed to be no obvious pattern emerging from these initial results. I suspect that this is due to the significantly higher unique word count for astrobiology papers (see point B below).\n",
    "<img src=\"astrobio_summary.png\",width=600>\n",
    " \n",
    "B. The relationship will be correlated with the diversity of unique words used within the training corpus of text representing the subdomain. This is to say that a subdomain with a larger variety of unique words (combinations of letters) will be more challenging to for the LSTM ANN to generate than a training corpus with fewer unique words. I hypothesize that more data will be needed to achieve a high degree of similarity between generated text and training text in some fields than others and that this will similarly correspond to unique word count. \n",
    "\n",
    "| Astronomy Domain  | Training Size  | Unique Word Count  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| <span style=\"color:green\">Black Hole</span>     | <span style=\"color:green\">1K</span> | <span style=\"color:green\">4134</span> |\n",
    "| <span style=\"color:green\">Black Hole</span>      | <span style=\"color:green\">5K</span>      |  <span style=\"color:green\">15203</span> |\n",
    "| <span style=\"color:green\">Black Hole</span> | <span style=\"color:green\">10K</span>      |  <span style=\"color:green\">26095</span>  |  \n",
    "| <span style=\"color:green\">Black Hole</span>     | <span style=\"color:green\">20K</span> | <span style=\"color:green\">45761</span> |  \n",
    "| <span style=\"color:blue\">Astrobiology</span>      | <span style=\"color:blue\">1K</span>      |  <span style=\"color:blue\">5217</span>  |   \n",
    "| <span style=\"color:blue\">Astrobiology</span> | <span style=\"color:blue\">5K</span>      |  <span style=\"color:blue\">20324</span>  |   \n",
    "| <span style=\"color:blue\">Astrobiology</span>      | <span style=\"color:blue\">10K</span> | <span style=\"color:blue\">34104</span> |   \n",
    "| <span style=\"color:blue\">Astrobiology</span>      | <span style=\"color:blue\">20K</span>      |  <span style=\"color:blue\">56703</span> |   \n",
    "| <span style=\"color:orange\">Exoplanets</span> | <span style=\"color:orange\">1K</span>   |   <span style=\"color:orange\">4162</span>  |   \n",
    "| <span style=\"color:orange\">Exoplanets</span>      | <span style=\"color:orange\">5K</span> | <span style=\"color:orange\">14143</span> |   \n",
    "| <span style=\"color:orange\">Exoplanets</span>      | <span style=\"color:orange\">10K</span>     |  <span style=\"color:orange\">23175</span>  |   \n",
    "| <span style=\"color:orange\">Exoplanets</span> | <span style=\"color:orange\">20K</span>      |  <span style=\"color:orange\">38301</span> |  \n",
    "\n",
    "The above hypothesis based on unique wordcount only holds true for the astrobiology titles tested in this analysis as there are not substantical differences between Black Hole titles and Exoplanet titles in regards to unique word count.\n",
    "\n",
    "C. I also performed an analysis using the presence of non-ASCII characters in the training and model-generated titles.\n",
    "I compared the proportion of non-ASCII characters per title containing non-ASCII characters to that of titles in the training corpus itself.\n",
    "\n",
    "| Astronomy Domain  | Training Size  | Non-ASCII Training  | Non-ASCII Test  |\n",
    "| ------------- |:-------------:| -----:| -----:|\n",
    "| <span style=\"color:green\">Black Hole</span>     | <span style=\"color:green\">1K</span> | <span style=\"color:green\">3</span> | <span style=\"color:green\">25</span> |\n",
    "| <span style=\"color:green\">Black Hole</span>      | <span style=\"color:green\">5K</span>      |  <span style=\"color:green\">3</span> | <span style=\"color:green\">26</span> |\n",
    "| <span style=\"color:green\">Black Hole</span> | <span style=\"color:green\">10K</span>      |  <span style=\"color:green\">3</span>  |  <span style=\"color:green\">6</span> |\n",
    "| <span style=\"color:green\">Black Hole</span>     | <span style=\"color:green\">20K</span> | <span style=\"color:green\">3</span> |  <span style=\"color:green\">6</span> |\n",
    "| <span style=\"color:blue\">Astrobiology</span>      | <span style=\"color:blue\">1K</span>      |  <span style=\"color:blue\">3</span>  |   <span style=\"color:blue\">8</span>  |   \n",
    "| <span style=\"color:blue\">Astrobiology</span> | <span style=\"color:blue\">5K</span>      |  <span style=\"color:blue\">2</span>  |   <span style=\"color:blue\">9</span>  |   \n",
    "| <span style=\"color:blue\">Astrobiology</span>      | <span style=\"color:blue\">10K</span> | <span style=\"color:blue\">3</span> |   <span style=\"color:blue\">15</span>  |   \n",
    "| <span style=\"color:blue\">Astrobiology</span>      | <span style=\"color:blue\">20K</span>      |  <span style=\"color:blue\">3</span> |   <span style=\"color:blue\">15</span>  |   \n",
    "| <span style=\"color:orange\">Exoplanets</span> | <span style=\"color:orange\">1K</span>   |   <span style=\"color:orange\">3</span>  |   <span style=\"color:orange\">7</span>  |   \n",
    "| <span style=\"color:orange\">Exoplanets</span>      | <span style=\"color:orange\">5K</span> | <span style=\"color:orange\">3</span> |   <span style=\"color:orange\">7</span>  |   \n",
    "| <span style=\"color:orange\">Exoplanets</span>      | <span style=\"color:orange\">10K</span>     |  <span style=\"color:orange\">2</span>  |   <span style=\"color:orange\">4</span>  |   \n",
    "| <span style=\"color:orange\">Exoplanets</span> | <span style=\"color:orange\">20K</span>      |  <span style=\"color:orange\">2</span> |  <span style=\"color:orange\">4</span>  |   \n",
    "\n",
    "Again you can see from the above results that astrobiology is the only subdomain that deviates from the trend wherein increasing the training set size makes the prevelance of non-ASCII characters more realistic.\n",
    "\n",
    "** Further discussion of these results will be incorporated into the final writeup of these analyses.**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
