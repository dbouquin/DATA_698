{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering and transforming data for use in [Torch](https://github.com/jcjohnson/torch-rnn)\n",
    "The below scripts are used to pull data from the NASA Astrophysics Data System API and convert that data into a text file. The screenshots at the end show Torch being used in the Terminal to create .h5 and .json files for use in training an LSTM RNN. I also run a small test of the neural network to generate a new title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modules for ADS API and data transformations\n",
    "import os\n",
    "import ads as ads \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure API and execute API call for 1,000 most recent \"black hole\" papers\n",
    "* I will also conduct calls for ten thousand and one hundred thousand records using these same methods - 1,000 set is for example    \n",
    "* Subsequently I will contruct three different datasets of one thousand, ten thousand, and one hundred thousand records and do this with three different topics for comparison.   \n",
    "* This demo will only be for \"black hole\" papers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"ADS_DEV_KEY\"] = \"kNUoTurJ5TXV9hsw9KQN1k8wH4U0D7Oy0CJoOvyw\"\n",
    "ads.config.token = 'ADS_DEV_KEY' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for papers and retrieve associated bibcodes, titles, and abstracts\n",
    "Initially I will just work to generate titles with my ANN. I will do this using the titles from this API call as a training dataset. I will be able to compare generated titles to the training titles to see how close I can get to the training titles. For my project I may experiment with using abstracts instead of titles if time allows. Titles are just much faster to work with because they are small so the processing runs much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "papers1 = list(ads.SearchQuery(q= \"black hole\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=20 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find titles \n",
    "t = []\n",
    "for i in papers1:\n",
    "    title1 = i.title\n",
    "    t.append(title1)\n",
    "title = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the resulting titles into a dataframe so that they can be easily converted into a text file for use in [Torch](https://github.com/jcjohnson/torch-rnn). Torch needs a .txt file in order to run their processing Python module to create the necessary .json and .h5 files that the RNN library requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"blackhole_1000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get average number of characters in a title for use in torch\n",
    "sum(df['Title'].str.len())/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create .json and .h5 files using Torch's [preprocessing scripts](https://github.com/jcjohnson/torch-rnn/blob/master/scripts/preprocess.py):\n",
    "![Data Conversion](Torch_File_Conversion.png)\n",
    "  \n",
    "Resulting new files needed for training the model:\n",
    "![New Files](New_Files.png)\n",
    "   \n",
    "We can now do a test run using our tiny dataset to train Torch's LSTM implementation. The training takes 50 \"Epochs\" to run:   \n",
    "![Training](Training.png)\n",
    "\n",
    "After the training completes, we see how long it took to run:\n",
    "![Training Time](Training_End.png)\n",
    "\n",
    "Then we can create a sample title generated by the neural network:\n",
    "![Sample print to console](Sample.png)\n",
    "\n",
    "We can also write a sample to a text file:\n",
    "![Sample write to txt](Sample_textfile.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This sample is trained on a very tiny dataset, but it functions as a proof of concept. I can convert the data from the ADS API into files that can be used in Torch's RNN library to generate new text. From here I can work on increasing the size of the training sets and using training sets from different subdomains of astronomy. I can also work on adjusting Torch's \"temperature\" flag to see how this impacts the model; the temperature flag represents adjustments that can be made to the model's [softmax function](https://en.wikipedia.org/wiki/Softmax_function). In this way I can do the analytical work needed to determine how similar my ANN generated text is to the training text I use and see if these measures differ between different subdomains of astronomy (I created an example of this sort of analysis [here](https://github.com/dbouquin/DATA_698/blob/master/ADS_data_exploration_698.ipynb)). This degree of similarity between the generated text and the original training text can provide insight into the complexity inherent to astronomy-specific language and inform literacy studies in the field."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
