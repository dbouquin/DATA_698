{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modules for ADS API and data transformations\n",
    "import os\n",
    "import ads as ads \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# API config\n",
    "os.environ[\"ADS_DEV_KEY\"] = \"kNUoTurJ5TXV9hsw9KQN1k8wH4U0D7Oy0CJoOvyw\"\n",
    "ads.config.token = 'ADS_DEV_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I selected three different fields within astonomy and astrophysics for comparisons. I chose to run searches for articles in popular and emerging areas and selected search terms from the [Unified Astronomy Thesaurus](http://astrothesaurus.org/). The terms I selected from the UAT hierarchy are all second level terms with more than one child term. You can visualize the hierarchy and see the context of the selected terms by using the sorting tool available [here](http://uat.altbibl.io/sort/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Astrobiology datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Astrobiology searches \n",
    "# Interdisciplinary field\n",
    "# These will be training datasets\n",
    "\n",
    "# 1,000 Astrobiology papers\n",
    "astrobio_1 = list(ads.SearchQuery(q= \"Astrobiology\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=20 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5,000 Astrobiology papers\n",
    "astrobio_2 = list(ads.SearchQuery(q= \"Astrobiology\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10,000 Astrobiology papers\n",
    "astrobio_3 = list(ads.SearchQuery(q= \"Astrobiology\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=200 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 20,000 Astrobiology papers\n",
    "# The API times out with larger queries\n",
    "astrobio_4 = list(ads.SearchQuery(q= \"Astrobiology\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=400 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 35,000 Astrobiology papers\n",
    "# The API times out with larger queries\n",
    "astrobio_5 = list(ads.SearchQuery(q= \"Astrobiology\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=700 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note - Multiple long queries cause the API to time out. They must be run separately and in different cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 1,000 astrobio\n",
    "# find titles \n",
    "t = []\n",
    "for i in astrobio_1:\n",
    "    astrobio_title1 = i.title\n",
    "    t.append(astrobio_title1)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"astrobio_1000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5,000 astrobio\n",
    "# find titles \n",
    "t = []\n",
    "for i in astrobio_2:\n",
    "    astrobio_title2 = i.title\n",
    "    t.append(astrobio_title2)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"astrobio_5000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10,000 astrobio\n",
    "# find titles \n",
    "t = []\n",
    "for i in astrobio_3:\n",
    "    astrobio_title3 = i.title\n",
    "    t.append(astrobio_title3)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"astrobio_10000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20,000 astrobio\n",
    "# find titles \n",
    "t = []\n",
    "for i in astrobio_4:\n",
    "    astrobio_title4 = i.title\n",
    "    t.append(astrobio_title4)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"astrobio_20000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 35,000 astrobio\n",
    "# find titles \n",
    "t = []\n",
    "for i in astrobio_5:\n",
    "    astrobio_title5 = i.title\n",
    "    t.append(astrobio_title5)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"astrobio_35000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.36205960510901"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of characters in astrobiology titles\n",
    "df = pd.read_csv('Final_Datasets/astrobiology/astrobio_35000.txt', names=['Title'])\n",
    "\n",
    "word_count_title = df['Title'].str.len()\n",
    "word_count_title.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Hole Datasetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Black Hole searches\n",
    "# Popular topic in High Engery Astrophysics\n",
    "# These will be training datasets\n",
    "\n",
    "# 1,000 Black Hole papers\n",
    "blackhole_1 = list(ads.SearchQuery(q= \"Black Hole\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=20 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5,000 Black Hole papers\n",
    "blackhole_2 = list(ads.SearchQuery(q= \"Black Hole\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10,000 Black Hole papers\n",
    "blackhole_3 = list(ads.SearchQuery(q= \"Black Hole\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=200 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20,000 Black Hole papers\n",
    "blackhole_4 = list(ads.SearchQuery(q= \"Black Hole\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=400 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 35,000 Black Hole papers\n",
    "# The API times out with larger queries\n",
    "blackhole_5 = list(ads.SearchQuery(q= \"Black Hole\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=700 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 1,000 Black Hole\n",
    "# find titles \n",
    "t = []\n",
    "for i in blackhole_1:\n",
    "    blackhole_title1 = i.title\n",
    "    t.append(blackhole_title1)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"blackhole_1000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 5,000 Black Hole\n",
    "# find titles \n",
    "t = []\n",
    "for i in blackhole_2:\n",
    "    blackhole_title2 = i.title\n",
    "    t.append(blackhole_title2)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"blackhole_5000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 10,000 Black Hole\n",
    "# find titles \n",
    "t = []\n",
    "for i in blackhole_3:\n",
    "    blackhole_title3 = i.title\n",
    "    t.append(blackhole_title3)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"blackhole_10000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 20,000 Black Hole\n",
    "# find titles \n",
    "t = []\n",
    "for i in blackhole_4:\n",
    "    blackhole_title4 = i.title\n",
    "    t.append(blackhole_title4)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"blackhole_20000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 35,000 Black Hole\n",
    "# find titles \n",
    "t = []\n",
    "for i in blackhole_5:\n",
    "    blackhole_title5 = i.title\n",
    "    t.append(blackhole_title5)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"blackhole_35000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.62978942255494"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of characters in Black Hole titles\n",
    "df = pd.read_csv('Final_Datasets/blackholes/blackhole_35000.txt', names=['Title'])\n",
    "\n",
    "word_count_title = df['Title'].str.len()\n",
    "word_count_title.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exoplanet Detection Methods Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Exoplanet Detection Methods searches\n",
    "# Popular topic in exoplanet astronomy\n",
    "# These will be training datasets\n",
    "\n",
    "# 1,000 Exoplanet Detection Methods papers\n",
    "exoplanet_1 = list(ads.SearchQuery(q= \"Exoplanet Detection Methods\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=20 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5,000 Exoplanet Detection Methods papers\n",
    "exoplanet_2 = list(ads.SearchQuery(q= \"Exoplanet Detection Methods\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 10,000 Exoplanet Detection Methods papers\n",
    "exoplanet_3 = list(ads.SearchQuery(q= \"Exoplanet Detection Methods\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=200 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20,000 Exoplanet Detection Methods papers\n",
    "exoplanet_4 = list(ads.SearchQuery(q= \"Exoplanet Detection Methods\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=400 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 35,000 Exoplanet Detection Methods papers\n",
    "# The API times out with larger queries\n",
    "exoplanet_5 = list(ads.SearchQuery(q= \"Exoplanet Detection Methods\", fl=['bibcode', 'title', 'abstract'], sort='pubdate', max_pages=700 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 1,000 Exoplanet Detection Methods\n",
    "# find titles \n",
    "t = []\n",
    "for i in exoplanet_1:\n",
    "    exoplanet_title1 = i.title\n",
    "    t.append(exoplanet_title1)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"exoplanet_1000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 5,000 Exoplanet Detection Methods\n",
    "# find titles \n",
    "t = []\n",
    "for i in exoplanet_2:\n",
    "    exoplanet_title2 = i.title\n",
    "    t.append(exoplanet_title2)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"exoplanet_5000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 10,000 Exoplanet Detection Methods\n",
    "# find titles \n",
    "t = []\n",
    "for i in exoplanet_3:\n",
    "    exoplanet_title3 = i.title\n",
    "    t.append(exoplanet_title3)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"exoplanet_10000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 20,000 Exoplanet Detection Methods\n",
    "# find titles \n",
    "t = []\n",
    "for i in exoplanet_4:\n",
    "    exoplanet_title4 = i.title\n",
    "    t.append(exoplanet_title4)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"exoplanet_20000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the datasets and write to files\n",
    "# 35,000 Exoplanet Detection Methods\n",
    "# find titles \n",
    "t = []\n",
    "for i in exoplanet_5:\n",
    "    exoplanet_title5 = i.title\n",
    "    t.append(exoplanet_title5)\n",
    "title = t\n",
    "\n",
    "# create an initial df (only 1 column) and clean it up\n",
    "df = pd.DataFrame({'Title' : title\n",
    "  })\n",
    "df['Title'] = df['Title'].str.get(0)\n",
    "\n",
    "# write to .txt\n",
    "df.to_csv(\"exoplanet_35000.txt\", sep=' ', header=None, index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.13300318358684"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of characters in Exoplanet Detection Methods titles\n",
    "df = pd.read_csv('Final_Datasets/exoplanets/exoplanet_35000.txt', names=['Title'])\n",
    "\n",
    "word_count_title = df['Title'].str.len()\n",
    "word_count_title.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
